# train-llm-tutorial
How to Fine-Tune LLMs in 2024 with Hugging Face

https://www.philschmid.de/fine-tune-llms-in-2024-with-trl

models evaluete:
code-llama-7b-text-to-sql: Accuracy: 78.20%
code-mistral-7B-text-to-sql: Accuracy: 78.20% ???? hernya-s

Из сравнения (vacation_queries_with_short_queries.xlsx) можно сделать вывод:
1) декомпозиция вопросов Мистралем с 10 примерами лучше, чем без примеров
2) декомпозиция вопросов от Опенчат с 10 примерами лучше чем декомпозиция Мистраля с 10 примерами